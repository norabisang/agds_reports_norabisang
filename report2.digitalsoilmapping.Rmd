---
title: "agds_report2_norabisang_digitalsoilmapping"
output: html_document
date: "2025-10-30"
---

```{r setup, include=FALSE}

```
Setup

```{r}
#install.packages("renv")
library(renv)
library(terra)
library(here)
getwd()

```



```{r}
list.files()
getwd()
#loading data

df_full <- readRDS(here::here("tutorial_digital_soil_mapping-main", "data", "df_full.rds"))
file.exists(file.path("tutorial_digital_soil_mapping-main", "data", "df_full.rds"))
getwd()
write.csv(df_full, here::here("data-raw", "df_full.rds"), row.names = FALSE)


# Load soil data from sampling locations
readr::write_csv(df_full, "data-raw/df_full")

#get an overview of the df_full 
head(df_full)
names(df_full)

```


```{r}
getwd()


# Pfade definieren
src <- here::here("tutorial_digital_soil_mapping-main", "data-raw")
dst <- here::here("data-raw")

# Sicherstellen, dass Zielordner existiert
if (!dir.exists(dst)) {
  dir.create(dst, recursive = TRUE)
  message("Zielordner 'data-raw' wurde erstellt.")
}

# Dateien und Unterordner rekursiv kopieren
message("Kopiere Dateien von:\n", src, "\nnach:\n", dst)
success <- file.copy(from = src, to = dirname(dst), recursive = TRUE)

# Prüfen, ob alles geklappt hat
if (success) {
  message("data successfully copied")

  # deletion of old file
  unlink(src, recursive = TRUE)
  message("️old file deleted: ", src)
} else {
  message("Copying not successful, check again")
}





```

```{r}
#now geodata
# Get a list with the path to all raster files
list_raster <- list.files(
  here::here("data-raw/geodata/covariates/"),
  full.names = TRUE
)

# Display data (lapply to clean names)
lapply(
  list_raster, 
  function(x) sub(".*/(.*)", "\\1", x)
) |> 
  unlist() |> 
  head(5) |> 
  print()


```
```{r}
df_obs <- readr::read_csv(
  here::here("data-raw/soildata/berne_soil_sampling_locations.csv")
  )

# Display data
head(df_obs) |> 
  knitr::kable()
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.



```{r}
# Load a raster file as example: Picking the slope profile at 2 m resolution
raster_example <- terra::rast(
  here::here("data-raw/geodata/covariates/Se_slope2m.tif")
  )
raster_example
```
The code chunks filtered for a random sub-sample of 15 variables. As described in Chapter 5, your task will be to investigate all covariates and find the ones that can best be used for your modelling task.



```{r}
# Plot raster example
terra::plot(raster_example)
```

To have more flexibility with visualising the data, we can use the ggplot() in combination with the {tidyterra} package.


```{r}
library(tidyterra)

# To have some more flexibility, we can plot this in the ggplot-style as such:
ggplot2::ggplot() +
  tidyterra::geom_spatraster(data = raster_example) +
  ggplot2::scale_fill_viridis_c(
    na.value = NA,
    option = "magma",
    name = "Slope (%) \n"
    ) +
  ggplot2::theme_bw() +
  ggplot2::scale_x_continuous(expand = c(0, 0)) +  # avoid gap between plotting area and axis
  ggplot2::scale_y_continuous(expand = c(0, 0)) +
  ggplot2::labs(title = "Slope of the Study Area")

```
Note that the second plot has different coordinates than the upper one. That is because the data was automatically projected to the World Geodetic System (WGS84, ESPG: 4326).




the code chunk below help to put our map in a bit more context. A larger map background would be useful to get a better orientation of our location. Also, it would be nice to see where our sampling locations are and to differentiate these locations by whether they are part of the training or testing dataset.
```{r}
# To get our map working correctly, we have to ensure that all the input data
# is in the same coordinate system. Since our Bern data is in the Swiss 
# coordinate system, we have to transform the sampling locations to the 
# World Geodetic System first.
# To look up EPSG Codes: https://epsg.io/
# World Geodetic System 1984:  4326
# Swiss CH1903+ / LV95: 2056

# For the raster:
rasta <- terra::project(raster_example, "+init=EPSG:4326")

# Let's make a function for transforming the sampling locations:
change_coords <- function(data, from_CRS, to_CRS) {
  
  # Check if data input is correct
  if (!all(names(data) %in% c("id", "lat", "lon"))) {
    stop("Input data needs variables: id, lat, lon")
  }
  
  # Create simple feature for old CRS
  sf_old_crs <- sf::st_as_sf(data, coords = c("lon", "lat"), crs = from_CRS)
  
  # Transform to new CRS
  sf_new_crs     <- sf::st_transform(sf_old_crs, crs = to_CRS)
  sf_new_crs$lat <- sf::st_coordinates(sf_new_crs)[, "Y"]
  sf_new_crs$lon <- sf::st_coordinates(sf_new_crs)[, "X"]
  
  sf_new_crs <- sf_new_crs |> dplyr::as_tibble() |> dplyr::select(id, lat, lon)
  
  # Return new CRS
  return(sf_new_crs)
}

# Transform dataframes
coord_train <- df_obs |> 
  dplyr::filter(dataset == "calibration") |> 
  dplyr::select(site_id_unique, x, y) |> 
  dplyr::rename(id = site_id_unique, lon = x, lat = y) |> 
  change_coords(
    from_CRS = 2056, 
    to_CRS = 4326
    )

coord_test <- df_obs |> 
  dplyr::filter(dataset == "validation") |> 
  dplyr::select(site_id_unique, x, y) |> 
  dplyr::rename(id = site_id_unique, lon = x, lat = y) |> 
  change_coords(
    from_CRS = 2056, 
    to_CRS = 4326
    )




# Notes: 
# - This code may only work when installing the development branch of {leaflet}:
#install.packages("remotes")
library(remotes)
#remotes::install_github('rstudio/leaflet')
# - You might have to do library(terra) for R to find functions needed in the backend
library(terra)

# Let's get a nice color palette now for easy reference
pal <- leaflet::colorNumeric(
  "magma",
  terra::values(rasta),           #I here changed r to rasta as defined above
  na.color = "transparent"
  )

# Next, we build a leaflet map
leaflet::leaflet() |> 
  # As base maps, use two provided by ESRI
  leaflet::addProviderTiles(leaflet::providers$Esri.WorldImagery, group = "World Imagery") |>
  leaflet::addProviderTiles(leaflet::providers$Esri.WorldTopoMap, group = "World Topo") |>
  # Add our raster file
  leaflet::addRasterImage(
    rasta,
    colors = pal,
    opacity = 0.6,
    group = "raster"
    ) |>
  # Add markers for sampling locations
  leaflet::addCircleMarkers(
    data = coord_train,
    lng = ~lon,  # Column name for x coordinates
    lat = ~lat,  # Column name for y coordinates
    group = "training",
    color = "black"
  ) |>
    leaflet::addCircleMarkers(
    data = coord_test,
    lng = ~lon,  # Column name for x coordinates
    lat = ~lat,  # Column name for y coordinates
    group = "validation",
    color = "red"
  ) |>
  # Add some layout and legend
  leaflet::addLayersControl(
    baseGroups = c("World Imagery","World Topo"),
    position = "topleft",
    options = leaflet::layersControlOptions(collapsed = FALSE),
    overlayGroups = c("raster", "training", "validation")
    ) |>
  leaflet::addLegend(
    pal = pal,
    values = terra::values(rasta),
    title = "Slope (%)")
```
Looking at plot above: 
You can check whether the slope raster file makes sense by comparing it against the base maps. Can you see how cliffs along the Aare river, hills, and even gravel quarries show high slope values. We also see that our testing dataset is randomly distributed across the area covered by the training dataset.






#Now into Data combination
```{r}
# Load all files as one batch
all_rasters <- terra::rast(list_raster)
all_rasters
```

Note that above, we have stacked only a random of all available raster data (list_raster) which we have generated previously.

Now, we do not want to have the covariates’ data from all cells in the raster file. Rather, we want to reduce our stacked rasters to the x and y coordinates for which we have soil sampling data. We can do this using the terra::extract() function. Then, we want to merge the two dataframes of soil data and covariates data by their coordinates. Since number of rows and the order of the covariate data is the same as the “Bern data” (soil samples), we can simply bind their columns with cbind():

```{r}
# Extract coordinates from sampling locations
sampling_xy <- df_obs |> 
  dplyr::select(x, y)

# From all rasters, extract values for sampling coordinates
df_covars <- terra::extract(
  all_rasters,  # The raster we want to extract from
  sampling_xy,  # A matrix of x and y values to extract for
  ID = FALSE    # To not add a default ID column to the output
  )

df_full <- cbind(df_obs, df_covars)
head(df_full) |> 
  knitr::kable() 

```


Now, not all our covariates may be continuous variables and therefore have to be encoded as factors. As an easy check, we can take the original corvariates data and check for the number of unique values in each raster. If the variable is continuous, we expect that there are a lot of different values - at maximum 1052 different values because we have that many entries. So, let’s have a look and assume that variables with 10 or less different values are categorical variables.

```{r}
vars_categorical <- df_covars |> 
  
  # Get number of distinct values per variable
  dplyr::summarise(dplyr::across(dplyr::everything(), ~dplyr::n_distinct(.))) |> 
  
  # Turn df into long format for easy filtering
  tidyr::pivot_longer(
    dplyr::everything(), 
    names_to = "variable", 
    values_to = "n"
    ) |> 
  
  # Filter out variables with 10 or less distinct values
  dplyr::filter(n <= 10) |>
  
  # Extract the names of these variables
  dplyr::pull('variable')

cat("Variables with less than 10 distinct values:", 
    ifelse(length(vars_categorical) == 0, "none", vars_categorical))
```

Now that we have the names of the categorical values, we can mutate these columns in our data frame using the base function as.factor()

```{r}
df_full <- df_full |> 
  dplyr::mutate(dplyr::across(all_of(vars_categorical), ~as.factor(.)))

```

Now we have to ensure we only use data that is informative and remove what has to many missing variables.
```{r}
# Get number of rows to calculate percentages
n_rows <- nrow(df_full)

# Get number of distinct values per variable
df_full |> 
  dplyr::summarise(dplyr::across(dplyr::everything(), 
                                 ~ length(.) - sum(is.na(.)))) |> 
  tidyr::pivot_longer(dplyr::everything(), 
                      names_to = "variable", 
                      values_to = "n") |>
  dplyr::mutate(perc_available = round(n / n_rows * 100)) |> 
  dplyr::arrange(perc_available) |> 
  head(10) |> 
  knitr::kable()



#no variable with a substantial amount of missing data. Generally, only pH measurements are lacking, which we should keep in mind when making predictions and inferences



#Another great way to explore your data, is using the {visdat} package:

df_full |> 
  dplyr::select(1:20) |>   # reduce data for readability of the plot
  visdat::vis_miss()
```

We are not missing any data in the covariate data. (Mostly sampled data, pH and timeset data is missing.) 
Missing data is mostly from the same entries, so if we keep only entries where we have pH data, we have a dataset with pracitally no missing data.

```{r}
if (!dir.exists(here::here("data"))) system(paste0("mkdir ", here::here("data")))
saveRDS(df_full, 
        here::here("data/df_full.rds"))
```


Model training

```{r}

head(df_full) |> 
  knitr::kable()
```

First, we have to specify our target and predictor variables. Then, we have to split our dataset into a training and a testing set (here already defined in df_full$dataset as "validation" or "calibration"). Random Forest models cannot deal with NA values, so we have to remove these from our training set.


```{r}
# Specify target: if waterlogged at 100
# Make sure target variable is categorical
df_full$waterlog.100 <- as.factor(df_full$waterlog.100)
levels(df_full$waterlog.100)

#now i check the balance (to see if special weighing is needed before RF training)
table(df_full$waterlog.100)
prop.table(table(df_full$waterlog.100))
```

Interpretation of balance exercize 5.1

There is moderate imbalance, but not to severe.(like 90/10, or 95/5.)

I can thus train RF classifier w.o. class weighting first.
BUT: accuracy of the model alone needs to be looked at with caution as it would give ~64% accuracy by just always predicting “0” so more tests could be helpful like : Precision, F1, AUC 

' @AddFurtherMetrics not just accuracy below but in confusion matrix i already have. 
Accuracy, Sensitivity, Specificity, Precision, Kappa, Balanced Accuracy what additionally but necessarliy could be added is AUC and F1 


```{r}
target <- "waterlog.100"
predictors_all <- names(df_full)[14:ncol(df_full)]

# Specify predictors_all: Remove soil sampling and observational data
predictors_all <- names(df_full)[14:ncol(df_full)]

cat("The target is:", target,
    "\nThe predictors_all are:", paste0(predictors_all[1:8], sep = ", "), "...")
```
```{r}
# Split dataset into training and testing sets
df_train <- df_full |> dplyr::filter(dataset == "calibration")
df_test  <- df_full |> dplyr::filter(dataset == "validation")

# Filter out any NA to avoid error when running a Random Forest
df_train <- df_train |> tidyr::drop_na()
df_test <- df_test   |> tidyr::drop_na()

# A little bit of verbose (=ausführlich) output:
n_tot <- nrow(df_train) + nrow(df_test)

perc_cal <- (nrow(df_train) / n_tot) |> round(2) * 100
perc_val <- (nrow(df_test)  / n_tot) |> round(2) * 100

cat("For model training, we have a calibration / validation split of: ",
    perc_cal, "/", perc_val, "%")
```

The modelling task is to predict watterlogging at 100cm. Let’s start using the default hyperparameters used by ranger::ranger().
```{r}
?ranger::ranger


# ranger() crashes when using tibbles (a bit like lazy dataframes), so we are using the
# base R notation to enter the data
# Welche Spalten fehlen?
setdiff(predictors_all, colnames(df_train))

library(ranger)

rf_basic <- ranger::ranger(
  y = df_train[, target],
  x = df_train[, predictors_all],
  importance = "permutation",
  probability = TRUE,          # now a classification model
  seed = 42,
  num.threads = parallel::detectCores() - 1
)

# Print a summary of fitted model
print(rf_basic)

```

(Note that: If our target variable was a categorical and not a continuous variable, we would have to set the argument probability = TRUE. The output would then be a probability map from 0-100%.)


This is the step at which you may want to reduce the number of predictors_all to avoid collinearity and the risk of overfitting. You may also want to optimize the hyperparameters for improving the model performance and generalisability. Different hyperparameter specifications of the Random Forest model that control the model complexity may be compared. A simple way to do that is to use the {caret} R package which provides machine learning wrapper functions for hyperparameter tuning (among many more functionalities). Its use in combination with Random Forest is demonstrated in Chapter 11 of AGDS book. Reducing the number of predictors_all and retaining only the most important ones is important for obtaining robust model generalisability and is approached by what is shown below.


Our model has 91 variables, but we don’t know anything about their role in influencing the model predictions and how important they are for achieving good predictions.
```{r}
# Let's run the basic model again but with recording the variable importance
rf_basic <- ranger::ranger( 
  y = df_train[, target],     # target variable
  x = df_train[, predictors_all],   # Predictor variables
  importance   = "permutation", # Pick permutation to calculate variable importance, 
   probability = TRUE,   
  seed = 42,  # Specify seed for randomization to reproduce the same model again, 

  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training

# Extract the variable importance and create a long tibble
vi_rf_basic <- rf_basic$variable.importance |>
  dplyr::bind_rows() |> 
  tidyr::pivot_longer(cols = dplyr::everything(), names_to = "variable")

# Plot variable importance, ordered by decreasing value
gg <- vi_rf_basic |> 
  ggplot2::ggplot(ggplot2::aes(x = reorder(variable, value), y = value)) +
  ggplot2::geom_bar(stat = "identity", fill = "grey50", width = 0.75) + 
  ggplot2::labs(
    y = "Change in OOB MSE after permutation", 
    x = "",
    title = "Variable importance based on OOB") +
  ggplot2::theme_classic() +
  ggplot2::coord_flip()

# Display plot
gg
```

Variable Selection
Reducing the number of predictors_all, while retaining model performance and improving model generalisability is the goal.noted that these algorithms don’t assess all possible combinations of predictors_all and may thus not find the “globally” optimal model. "Greedy search", or "stepwise regression" are often used. 

Boruta is available as an R package {Boruta}, is based on Random Forests, and performs a permutation of variables for determining their importance - as described in Chapter 12 of AGDS Book for model-agnostic variable importance estimation. The algorithm finally categorizes variables into "Rejected", "Tentative", and "Confirmed".

```{r}
#install.packages("Boruta")
library(Boruta)
set.seed(42)

# run the algorithm
bor <- Boruta::Boruta(
    y = df_train[, target], 
    x = df_train[, predictors_all],
    maxRuns = 50, # Number of iterations. Set to 30 or lower if it takes too long
    num.threads = parallel::detectCores()-1)

# obtain results: a data frame with all variables, ordered by their importance
df_bor <- Boruta::attStats(bor) |> 
  tibble::rownames_to_column() |> 
  dplyr::arrange(dplyr::desc(meanImp))

# plot the importance result  
ggplot2::ggplot(ggplot2::aes(x = reorder(rowname, meanImp), 
                             y = meanImp,
                             fill = decision), 
                data = df_bor) +
  ggplot2::geom_bar(stat = "identity", width = 0.75) + 
  ggplot2::scale_fill_manual(values = c("grey30", "tomato", "grey70")) + 
  ggplot2::labs(
    y = "Variable importance", 
    x = "",
    title = "Variable importance based on Boruta") +
  ggplot2::theme_classic() +
  ggplot2::coord_flip()

```


For the spatial upscaling in the context of digital soil mapping, let’s retain only the variables deemed important ("Confirmed") by the Boruta algorithm and retrain a final Random Forest model. 


```{r}
# get retained important variables
predictors_selected <- df_bor |> 
  dplyr::filter(decision == "Confirmed") |>
  dplyr::pull(rowname)

length(predictors_selected)
```
retraining random forest with only the confirmed predictor variables

```{r}
# re-train Random Forest model
rf_bor <- ranger::ranger( 
  y = df_train[, target],              # target variable
  x = df_train[, predictors_selected], # Predictor variables
  seed = 42, probability= TRUE,                          # Specify the seed for randomization to reproduce the same model again
  num.threads = parallel::detectCores() - 1) # Use all but one CPU core for quick model training

# quick report and performance of trained model object
rf_bor
```

Safe files
```{r}
# Save relevant data for model testing in the next chapter.
saveRDS(rf_bor,                   
        here::here("data/rf_for_waterlog.100.rds"))

saveRDS(df_train[, c(target, predictors_selected)],
        here::here("data/cal_for_waterlog.100.rds"))

saveRDS(df_test[, c(target, predictors_selected)],
        here::here("data/val_for_waterlog.100.rds"))

```

Model Analysis
```{r}
# Load random forest model
rf_bor   <- readRDS(here::here("data/rf_for_waterlog.100.rds"))
df_train <- readRDS(here::here("data/cal_for_waterlog.100.rds"))
df_test  <- readRDS(here::here("data/val_for_waterlog.100.rds"))
```

Exercize 5.2? 
Compare the skill of the models with all predictors_all and with the Boruta-informed reduced set of predictors_all.



I now want to compare which one does a better job predicting if waterlogged at 100cm or not the 
```{r}
# Load package
# Full model
pred_full <- predict(rf_basic, data = df_test)$predictions[, "1"]  # Wahrscheinlichkeit für Klasse 1
df_test$pred_full <- pred_full
pred_full_class <- ifelse(pred_full > 0.5, 1, 0)
pred_full_class <- factor(pred_full_class, levels = c(0,1))

# Boruta-reduced model
pred_bor <- predict(rf_bor, data = df_test)$predictions[, "1"]  # Wahrscheinlichkeit für Klasse 1
df_test$pred_bor <- pred_bor
pred_bor_class <- ifelse(pred_bor > 0.5, 1, 0)
pred_bor_class <- factor(pred_bor_class, levels = c(0,1))

# True labels
true_labels <- factor(df_test$waterlog.100, levels = c(0,1))

# Confusion matrices
library(caret)
cm_full <- confusionMatrix(pred_full_class, true_labels, positive = "1")
cm_bor  <- confusionMatrix(pred_bor_class,  true_labels, positive = "1")

cm_full
cm_bor



```

Interpretation of the CM. 
Accuracy: We can see that the Boruta model has a slightly higher accuracy, (predicts slightly more cases correctly).
Kappa: Agreement beyond chance:  Boruta’s Kappa is higher -> better agreement than full model, not just by chance
Boruta helps improving the model by removing less important variables, simplifying the model while actually improving it slightly as can be seen by the values of the CM. 

Balanced Accuracy > 0.77 for Boruta means that both classes are reasonably well predicted despite imbalance.
So as Boruta performes slightly better than the ful model across all metrics in the CM we can imply that reducing predictors improved generalisation, the model is less likely to overfit to training data and also performes a bit better on unseen test data.



5.2 Would the same model choice be made if we considered the OOB prediction error reported as part of the trained model object?
```{r}
rf_basic$prediction.error   # OOB error for full model = 0.1508364
rf_bor$prediction.error     # OOB error for Boruta model = 0.1442626

```
The OOB values show that the Boruta model has a slightly lower OOB error, which is consistent with the test metrics above. So I would make that same choice. 



Next, we load a mask of the area over which the soil will be mapped. Our target area to predict over is defined in the file area_to_be_mapped.tif.
labeling of 0 for pixels that are outside the area of interest and 1 for pixels within the area of interest.
```{r}
# Load area to be predicted
raster_mask <- terra::rast(here::here("data-raw/geodata/study_area/area_to_be_mapped.tif"))

# Turn target raster into a dataframe, 1 px = 1 cell
df_mask <- as.data.frame(raster_mask, xy = TRUE)

# Filter only for area of interest
df_mask <- df_mask |> 
  dplyr::filter(area_to_be_mapped == 1)

# Display df
head(df_mask) |> 
  knitr::kable()
```

load the selected set of covariates as maps. These will be as the basis for spatial upscaling and provide the predictor values across space, fed into the trained model for predicting soil pH across space.

```{r}
files_covariates <- list.files(
  path = here::here("data-raw/geodata/covariates/"), 
  pattern = ".tif$",
  recursive = TRUE, 
  full.names = TRUE
  )
```

 predictor rasters have to have the same resolution, extent, and coordinate reference system. This is the case as shown for two randomly picked examples.
 
```{r}
random_files <- sample(files_covariates, 2)
terra::rast(random_files[1])
terra::rast(random_files[2])

```
Loading of rasters for the selected predictor variables into a raster object (“stack” of multiple rasters).


```{r}
# Filter that list only for the variables used in the RF
preds_selected <- names(rf_bor$forest$covariate.levels)

#UNSURE IF I CANNOT JUST USE THIS: 
predictors_selected

list_raster <- list.files(
  here("data-raw/geodata/covariates/"),
  full.names = TRUE
)

#install.packages("stringr")
library(stringr)
files_selected <- list_raster |> 
  purrr::keep(~ str_detect(.x, str_c(predictors_selected, collapse = "|")))
# HERE I WENT LIKE THIS TOO AND JUST USED PREDICTORS_SELECTED

# Load all rasters as a stack
raster_covariates <- rast(files_selected)
```

Convert the raster stack into a dataframe

```{r}
# Get coordinates for which we want data
df_locations <- df_mask |> 
  dplyr::select(x, y)

# Extract data from covariate raster stack for all gridcells in the raster
df_predict <- terra::extract(
  raster_covariates,   # The raster we want to extract from
  df_locations,        # A matrix of x and y values to extract for
  ID = FALSE           # To not add a default ID column to the output
  )

df_predict <- cbind(df_locations, df_predict) |> 
  tidyr::drop_na()  # Se_TWI2m has a small number of missing data
```


To test our model for how well it predicts on data it has not used during model training, we first have to load the {ranger} package to load all functionalities to run a Random Forest with the predict() function. Alongside our model, we feed our validation data into the function and set its parallelization settings to use all but one of our computer’s cores.

```{r}
# Need to load {ranger} because ranger-object is used in predict()
library(ranger) 

# Make predictions for validation sites
prediction <- predict(
  rf_bor,           # RF model
  data = df_test,   # Predictor data
  num.threads = parallel::detectCores() - 1
  )

# Save predictions to validation df
df_test$pred <- prediction$predictions


```

extraction of standard metrics for a classification problem are things like: Accuracy, precision, AUC, F1

```{r}

# str(df_test$pred)
  # Calculate error
 # err <- df_test$waterlog.100 - df_test$pred
  
  # Calculate bias
 # bias <- mean(err, na.rm = TRUE) |> round(2)
  
  # Calculate RMSE
#  rmse <- sqrt(mean(err, na.rm = TRUE)) |> round(2)
  
  # Calculate R2
#r2 <- cor(df_test$waterlog.100, df_test$pred, method = ""pearson"")^2 |>  round(2)"

#I think all of the above is irrelevant for testing factors but only good for regression
#I will do a confusion matrix as suggested in 9.4.1. in the book

# Extract probability for class "1"
df_test$prob_1 <- df_test$pred[, "1"]

# Convert to predicted class (0/1) using 0.5 threshold
df_test$pred_class <- ifelse(df_test$prob_1 > 0.5, "1", "0")

# Convert to factors with same levels as target
df_test$pred_class <- factor(df_test$pred_class, levels = c("0", "1"))
df_test$waterlog.100 <- factor(df_test$waterlog.100, levels = c("0", "1"))

# Confusion matrix
library(caret)
library(ggplot2)
conf_matrix <- confusionMatrix(
  data = df_test$pred_class,
  reference = df_test$waterlog.100,
  positive = "1"
)
conf_matrix

mosaicplot(conf_matrix$table,
  main = "Confusion matrix"
)



```
So from the confusion matrix we can see that: 

108 samples were correctly predicted as not waterlogged.
50 samples were correctly predicted as waterlogged.
20 samples were missed (1, but predicted 0).
22 samples were false alarms (predicted 1, but in reality 0).



plot of metrics error visualization

```{r}
library(ggplot2)

ggplot(df_test, aes(x = prob_1, y = as.numeric(as.character(waterlog.100)))) +
  geom_jitter(height = 0.05, width = 0, alpha = 0.4, color = "tomato") +
  geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE, color = "blue") +
  labs(
    title = "Predicted Probability vs Observed Waterlogged (100 cm)",
    x = "Predicted Probability (Class = 1)",
    y = "Observed (0 = dry, 1 = waterlogged)"
  ) +
  theme_classic()

```
Looking at this plot we can say model’s predictions are reasonably well. The blue line shows that higher predicted probabilities correspond to a higher actual likelihood of being waterlogged. 


Create prediction maps
Spatial upscaling:
The fitted and tested model can now be used for spatially upscaling - creating a map of waterlogged at 100cm  values across our study area. For this, we again make predictions with our Random Forest model but we use our covariates dataframe for the study area, instead of only at the sampling locations as done above.
Now we run the model using only the Bor 
```{r}
# Make predictions using the RF model
prediction <- predict(
  rf_bor,              # RF model
  data = df_predict,   
  num.threads = parallel::detectCores() - 1)

# Attach predictions to dataframe
df_predict$prediction <- prediction$predictions

```



```{r}
# Extract dataframe with coordinates and predictions
df_map <- df_predict |>
  dplyr::select(x, y, prediction)

#check names
names(df_map)

df_map$prediction # to use terra::rast() we need to transform prediction matrix into separate names as expects one numeric column per raster layer, not matrix inside column.

# Split matrix into two numeric columns
df_map$pred_0 <- df_map$prediction[, "0"]
df_map$pred_1 <- df_map$prediction[, "1"]

# Drop the original matrix column
df_map$prediction <- NULL

# Check structure
head(df_map)

#The probability of being waterlogged at 100cm: 
library(terra)

# Turn dataframe probability of being waterlogged at 100cm into a raster
r_map <- terra::rast(
  df_map[, c("x", "y", "pred_1")],
  crs = "EPSG:2056",
  extent = terra::ext(raster_covariates)
)


#Now we can visualize this 
library(ggplot2)
library(tidyterra)

ggplot() +
  tidyterra::geom_spatraster(data = r_map) +
  scale_fill_viridis_c(
    na.value = NA,
    option = "viridis",
    name = "Prob. waterlogged"
  ) +
  theme_classic() +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  labs(
    title = "Predicted probability of being waterlogged at 100 cm",
    x = "Easting",
    y = "Northing"
  )




#Do i need this?

# Turn dataframe into a raster
raster_pred <- terra::rast(
  df_map,                  # Table to be transformed
  crs = "+init=epsg:2056", # Swiss coordinate system
  extent = terra::ext(raster_covariates) # Prescribe same extent as predictor rasters
  )
```



Finally write the predicted probability of being waterlogged raster into a GeoTIFF file
```{r}
# Save raster as .tif file
terra::writeRaster(
  r_map,
  "data/ra_predicted_ph0-10.tif",
  datatype = "FLT4S",  # FLT4S for floats, INT1U for integers (smaller file)
  filetype = "GTiff",  # GeoTiff format
  overwrite = TRUE     # Overwrite existing file
)
```



A thief just stole some of soil and I'm going after him.





I'm losing ground.