---
title: "agds_report1_norabisang - Phenology Modelling and Spatial Scaling"
author: "Nora Bisang"
output: html_document
date: "2025-12-16"
---
## 1. Introduction

In this exercize covers improvement of a temperature-based growing degree day (GDD) phenology model and spatial scaling. Phenological transition dates, which are derived from PhenoCam data are used to calibrate a leaf-out model. This is then applied spatially using DAYMET temperature data and compared to the MODIS MCD12Q2 phenology product.


# 2. data

setup of libraries
```{r}
library(keyring)
library(appeears)
library(sf)
library(here)
library(terra)
library(ggplot2)
library(leaflet)
library(htmlwidgets)
library(phenocamr)
library(dplyr)

```


## 2.1 PhenoCam data and phenology extraction
The phenocamr R package uses the PhenoCam API to access the latest GCC time series and derive phenology using a threshold-based methodology. The phenocamr API call also downloads DAYMET data, which includes both daily minimum and maximum data. 
```{r}
# download greenness time series,
# calculate phenology (phenophases),
# amend with DAYMET data
phenocamr::download_phenocam(
  site = "harvard$",
  veg_type = "DB",
  roi_id = "1000",
  daymet = TRUE,
  phenophase = TRUE,
  trim = 2022,
  out_dir = tempdir()
  )

harvard_phenocam_data <- readr::read_csv(
  file.path(tempdir(), "harvard_DB_1000_3day.csv"), 
  comment = "#"
  )

# reading in harvard phenology only retaining
# spring (rising) phenology for the GCC 90th
# percentile time series (the default)
harvard_phenology <- readr::read_csv(
  file.path(
    tempdir(),
    "harvard_DB_1000_3day_transition_dates.csv"
    ),
  comment = "#"
) |>
  dplyr::filter(
    direction == "rising",
    gcc_value == "gcc_90"
  )
```


### 2.2 Growing Degree Day (GDD) model
Growing degree days are defined as the cumulative sum of temperatures above a specified threshold (T0 , most commonly T0= 5°C). Here we implement the GDD. 
```{r}
# return mean daily temperature as well
# as formal dates (for plotting)
harvard_temp <- harvard_phenocam_data |>
  group_by(year) |>
  dplyr::mutate(
    tmean = (tmax..deg.c. + tmin..deg.c.)/2
  ) |> 
  dplyr::mutate(
    date = as.Date(date),
    gdd = cumsum(ifelse(tmean >= 5, tmean - 5, 0))
  ) |>
  dplyr::select(
    date,
    year,
    tmean,
    gdd
  ) |>
  ungroup()

# convert the harvard phenology data and only
# retain required data
harvard_phenology <- harvard_phenology |>
  mutate(
    doy = as.numeric(format(as.Date(transition_25),"%j")),
    year = as.numeric(format(as.Date(transition_25),"%Y"))
  ) |>
  select(
    year,
    doy,
    transition_25,
    threshold_25
    )
```


The GDD-based leaf-out model can be written in the form of a function that takes the temperature time series as its first argument, and as two parameters the temperature threshold above which temperatures are accumulated, and the critical GDD that determines the DOY at which leaf-out is predicted.
```{r}
gdd_model <- function(temp, par) {
  # split out parameters from a simple
  # vector of parameter values
  temp_threshold <- par[1]
  gdd_crit <- par[2]
  
  # accumulate growing degree days for
  # temperature data
  gdd <- cumsum(ifelse(temp > temp_threshold, temp - temp_threshold, 0))
  
  # figure out when the number of growing
  # degree days exceeds the minimum value
  # required for leaf development, only
  # return the first value
  doy <- unlist(which(gdd >= gdd_crit)[1])
  
  return(doy)
}
```


Running the model on the original 2010 data with the previously observed values and parameters 5°C for the temperature threshold and 130.44°C for the critical GDD, should yield a predicted leaf-out date that matches the observed leaf-out date of 114.
```{r}
# confirm that the model function
# returns expected results
# (we filter out the year 2010, but
# removing the filter would run the
# model for all years!)
prediction <- harvard_temp |>
  dplyr::filter(
    year == 2010
  ) |>
  group_by(year) |>
  summarize(
    pred = gdd_model(
      temp = tmean,
      par = c(5, 130.44)
    )  
  )

print(prediction)
```

### 2.3 Model calibration and optimization
The optimization minimizes the root mean squared error (RMSE) between the observed and the predicted values.
```{r}
# run model and compare to true values
# returns the RMSE
rmse_gdd <- function(par, data) {
  
  # split out data
  drivers <- data$drivers
  validation <- data$validation
  
  # calculate phenology predictions
  # and put in a data frame
  predictions <- drivers |>
    group_by(year) |>
    summarise(
      predictions = gdd_model(
        temp = tmean,
        par = par
      )
    )
  
  predictions <- left_join(predictions, validation, by = "year")
  
  rmse <- predictions |>
    summarise(
      rmse = sqrt(mean((predictions - doy)^2, na.rm = TRUE))
    ) |>
    pull(rmse)
  
  # return rmse value
  return(rmse)
}

```
 
 
Limitation of parameter space to reduce computation, as temperature thresholds fall within a range that is determined by physiological limits of plant activity.
This is the optimization routine, the optimal parameters for the temperature threshold and number of accumulation days respectively will be determined.
```{r}
# starting model parameters
par = c(0, 130)

# limits to the parameter space
lower <- c(-10,0)
upper <- c(45,500)

# data needs to be provided in a consistent
# single data file, a nested data structure
# will therefore accept non standard data formats
data <- list(
  drivers = harvard_temp,
  validation = harvard_phenology
  )

# optimize the model parameters
optim_par = GenSA::GenSA(
 par = par,
 fn = rmse_gdd,
 lower = lower,
 upper = upper,
 control = list(
   max.call = 4000
   ),
 data = data
)$par
```


These optimal parameters can now be plugged back into the model and run across all available years. 
```{r}
# run the model for all years
# to get the phenology predictions
predictions <- harvard_temp |>
  group_by(year) |>
  summarize(
   prediction = gdd_model(
    temp = tmean,
    par = optim_par
  )  
  )
```


### 2.4 Spatial scaling using DAYMET

A region around Boston in the eastern United States will be used, defined by the coordinates -72 to -70 East, and 42 to 44 North. 
The DAYMET raster data to scale the results spatially will be used. First both minimum and maximum temperature data will be downloaded and averaged to a mean daily value, using the appeears R package (Hufkens 2023).

The data is downloaded manually from github. Provided by geco-bern Fabian Alexander Bernhard. 
```{r}
library(ncdf4)
dest_file <- here::here("data-raw", "DAYMET_2012_aid0001.nc")
  
download.file(
    "https://github.com/fabern/handfull_of_pixels/raw/refs/heads/main/data/DAYMET.004_2012/DAYMET.004_1km_aid0001.nc",
    destfile = dest_file,
    mode = "wb"   # important for binary files like .nc
  )
r1 <- terra::rast(dest_file)  # Load with terra
terra::crs(r1) <- "epsg:4326" # Assign CRS

```


Definition of names and subsetting of the first 180 days for reduction of the memory footprint of the calculations.
```{r}
 # Calculate the daily mean values based on 'tmin' and 'tmax'
library(terra)  
mean_layer <- terra::mean(r1["tmax"], 
                            r1["tmin"])
  # fix the variable naming
varnames(mean_layer) <- "tmean"                             
names(mean_layer) <- gsub("tmax","tmean",names(mean_layer))
 
 # subset to first 180 days
  ma_nh_temp <- terra::subset(
    mean_layer,
    1:180
  )

terra::plot(mean_layer)
  
```


Appliance of the model to this raster using the the terra::app() function the growing degree day model gdd_model()
```{r}
predicted_phenology <- terra::app(
  ma_nh_temp,
  fun = gdd_model,
  par = optim_par
)
```


Plotting of the predicted phenology. 
Will result in an interactive map of the spatially scaled optimized growing degree model using DAYMET daily mean temperature data for tile 11935, including the greater Boston area in the south-east to the White Mountains in the north-west.
```{r}
library(leaflet)

# set te colour scale manually
pal <- colorNumeric(
  "magma",
  values(predicted_phenology),
  na.color = "transparent"
  )

# build the leaflet map
# using ESRI tile servers
# and the loaded demo raster
leaflet() |> 
  addProviderTiles(providers$Esri.WorldImagery, group = "World Imagery") |>
  addProviderTiles(providers$Esri.WorldTopoMap, group = "World Topo") |>
  addRasterImage(
    predicted_phenology,
    colors = pal,
    opacity = 0.8,
    group = "Phenology model results"
    ) |>
  addLayersControl(
    baseGroups = c("World Imagery","World Topo"),
    position = "topleft",
    options = layersControlOptions(collapsed = FALSE),
    overlayGroups = c("Phenology model results")
    ) |>
  addLegend(
    pal = pal,
    values = values(predicted_phenology),
    title = "DOY")
```


#Exercize Questions

## Question 1: Model Improvement 
How can you improve the model used to regionally scale the results in Chapter 6?
Provide at least three ways to improve the model used.
 
### 1.1: 
Cross-validation across years (temporal) and/or across space (spatial). 
This would allow assessment of the generalizability of the GDD model. 
If the model predicts well over different validation folds, this suggests that it captures true biological relationships rather than noise (-> Overfitting!). And thus would improve robustness and reliability of the model. 


### 1.2
Smoothing of the temperature (with eg Savitzky–Golay)
A smoothing window (of eg. 3days) could be used before accumulation of GDD. This would make our GDD less sensitive to isolated single day warm or cold spikes, which are not very likely to shift buddburst substantially, which would reduce variance caused by noise in early months of the year. At the same time the temperature rise dynamics would still be preserved. Further, smoothed temperature time series would lead to smoother residuals, which then would make downstream regression or kNN corrections more stable and less sensitive to random variance. 
    

### 1.3
Our GDD model assumes that each day with Temperature mean >5°C contributes equally to plant development, in reality though, plant development could also accelerate, be slower or plateau. We could apply a machine learning approach such as K-Nearest Neighbour (As in chapter 10), which is really good at pattern recognition and non-linear relationships. These would be beneficial in our model as especially when not only cumulative growing days matter but the climate variability patterns have influence on the (like frost events or really warm periods) it would be able to learn the relationship from the data with no need for an assumption about the form. 
  
  
  
## Question 2: Implementation Model Improvement 
Implement at least one of these methods

I implement the smoothing with the Savitzky-Golay-Filter used in chapter 5.3. 
```{r}
#install.packages("signal")
library(signal)

 NA %in% harvard_temp #no NA which is good :) else would return NAs and we could pre-fill missing days (with interpolation)

harvard_temp.smoothed <- harvard_temp %>%
  group_by(year) %>%
  mutate(
    tmean_smooth = signal::sgolayfilt(tmean, p = 3, n = 5))  # smaller n for daily data
 
#usually for GDD calculations a window of n=3-7 is used. I choose a 5-day moving window (2 days before and 2 after), which smooths out random daily noise but keeps the overall warming trend intact.
#Polynomial of 3 matches as can capture slight “S”-shapes, which are typical in temperature curves, without overfitting.


harvard_temp.smoothed <- harvard_temp.smoothed %>%
  mutate(
    gdd = cumsum(ifelse(tmean_smooth >= 5, tmean_smooth - 5, 0))
  )


```
 #HERE USE DO ALSO ANALYSE IT OR IMPLEMENT!!!!!

## Question 3: Statistical Comparison
Statistically compare the results with the MODIS MCD12Q2 phenology product.
### 3.1 compare the data spatially 
### 3.2 describe why you might or might not see the same patterns
### 3.3 consider that 2010 was a ‘special’ year for the north east of the US


###3.1

Spatial comparison that shows how the DOY differ between the prediction of the Model and the MODIS data.   
Loading of the MODIS phenology product. 
```{r}
# load libraries
library(geodata)

# download SRTM data
# This stores file srtm_38_03.tif in 
# subfolder elevation of tempdir()
geodata::elevation_3s(
    lat = 43,
    lon = -71,
    path = tempdir()
  )

# read the downloaded data
# use file.path() to combine

library(terra)
# My path is: 
dem_file <- file.path(tempdir(), "elevation", "srtm_22_04.tif")
# Loading of raster
dem <- rast(dem_file)
# Check if worked or no
dem
crs(dem)


```




```{r}
# load libraries
library(MODISTools)

#coordinates -72 to -70 East, and 42 to 44 North

# download and save phenology data
phenology <- MODISTools::mt_subset(
  product = "MCD12Q2",
  lat = 43,            #for coordinates I use midpoint of longitude/ latitude
  lon = -71,            
  band = "Greenup.Num_Modes_01",
  start = "2012-01-01",
  end = "2012-12-31",
  km_lr = 100,
  km_ab = 100,
  site_name = "Boston", 
  internal = TRUE,
  progress = FALSE
)

```


Conversion of the integer values, counted from 1970, to day-of-year values (using as.Date() and format()). We only consider phenological events in the first 200 days of the year.
```{r}
# screening of data
phenology <- phenology |>
  mutate(
    value = ifelse(value > 32656, NA, value),
    value = as.numeric(format(as.Date("1970-01-01") + value, "%j")),
    value = ifelse (value < 200, value, NA)
  )

```

 

Conversion of tidy data to a geospatial (terra SpatRast) format
```{r}
phenology_raster <- MODISTools::mt_to_terra(
  phenology,
  reproject = TRUE
)

```


Visualization
```{r}
library(terra)
library(ggplot2)
library(tidyterra)

# Ensure rasters align (resample GDD raster to MODIS grid if needed)
predicted_resampled <- terra::resample(predicted_phenology, phenology_raster, method = "near")

# Pixel-wise difference btw. DOY predicted by our model and the observed DOY from MODIS:
#positive ->model predicts later DOY than MODIS
#negative -> model predicts earlier DOY than MODIS
difference <- predicted_resampled - phenology_raster

# 1 Plot from MODIS observations
ggplot() +
  geom_spatraster(data = phenology_raster) +
  scale_fill_viridis_c(name = "MODIS DOY", na.value = NA) +
  theme_bw()

# 2 Plot of the  GDD predictions
ggplot() +
  geom_spatraster(data = predicted_resampled) +
  scale_fill_viridis_c(name = "GDD DOY", na.value = NA, option = "magma") +
  theme_bw()

# 3 Plot of difference (GDD - MODIS)
ggplot() +
  geom_spatraster(data = difference) +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0,
                       name = "GDD - MODIS DOY") +
  theme_bw()
```


Statistical comparison that shows that the DOY differ between the prediction of the Model and the MODIS data. 
```{r}
colnames(df) <- c("MODIS", "GDD")

cor(df$MODIS, df$GDD, use = "complete.obs") # 0.3886199
mean(df$GDD - df$MODIS, na.rm = TRUE) #9.973585



```


### 3.2

Pixelwise spatial comparison between the GDD phenology predictions and the MODIS observations shows moderate positive correlation with r = 0.39. THis indicates that the model captures large-scale spatial gradients in phenology. Both datasets show climatic gradients related to latitude and difference in temperature from coast to inland. However, the model predicts leaf-out on average 9.97 days later than observed by MODIS, which could be due to systematic positive bias. Reasons for that could be: differences in phenological definitions, spatial resolution, vegetation heterogeneity, as well as the  possibility of MODIS detecting canopy greening earlier than temperature-based leaf-out thresholds.

Similar spatial patterns are expected because both approaches are somehow linked to temperature: directly in the GDD model through accumulated mean temperature, and indirectly in the MODIS observations through temperature-driven vegetation greening. Still, several factors can lead to differences between the two products. As MODIS does not measure temperature but detects changes in surface reflectance, it can be influenced by cloud cover, snow, and sensor related noise. Further, the GDD model assumes homogeneous vegetation responses and does not account for heterogeneity in species composition, microclimate and topography. Differences in spatial resolution between the DAYMET-driven model and the MODIS observations could further contribute to mismatches, particularly in heterogeneous landscapes.


### 3.3
2010 was a special year as the DOY for leaf-out was earlier than normal.Leaf-out requires the accumulation of a certain amount of heat (GDD), so warmer springs reach the threshold sooner and thus result in earlier greening up. This indicates a warmer spring than normal. 
Below I calculated GDD accumulation  during early spring period (DOY 60–120) as I expect the biologically relevant window for bud development to lie in these days. Visible in the summary and plot are higher GDD values in 2010 and 2012 which indicate earlier spring warming that leads to earlier phenology and thus DOY for budd-out. In the mean temperature March-April is well visible that mean temperatures indeed were exceptionally high. 


```{r}
library(dplyr)
library(lubridate)

harvard_temp <- harvard_temp %>%
  mutate(doy = yday(date))   # create day-of-year column


spring_summary <- harvard_temp %>%
  filter(doy >= 60 & doy <= 120) %>%   # I choose days 60 -120 as this is ~spring 
  group_by(year) %>%
  summarize(
    mean_temp = mean(tmean, na.rm = TRUE),
    gdd_cum = sum(ifelse(tmean >= 5, tmean - 5, 0))
  )

spring_summary

#here as a visualization to see that temperature in 2010 was exceptionally warm (as was in 2012)
ggplot(spring_summary, aes(x = year)) +
  geom_line(aes(y = mean_temp), linewidth = 1, color = "limegreen") +
  geom_point(aes(y = mean_temp), color = "darkgreen") +
  labs(title = "Spring Temperature (march and april)",
       x = "year", y = "mean temperature (°C)") +
  theme_bw()





```








